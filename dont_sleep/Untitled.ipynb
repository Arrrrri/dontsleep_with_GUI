{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb42e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\AppData\\Local\\Temp\\ipykernel_6524\\3729294492.py:22: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = ImageOps.fit(image, size, Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 764ms/step\n",
      "[[0.999954   0.00004596]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "model = tensorflow.keras.models.load_model('C:/Users/82102/res/dont_sleep/converted_keras/keras_model.h5')\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "# Replace this with the path to your image\n",
    "image = Image.open('C:/Users/82102/res/dont_sleep/test_photo.jpg')\n",
    "\n",
    "#resize the image to a 224x224 with the same strategy as in TM2:\n",
    "#resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "\n",
    "#turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "\n",
    "# display the resized image\n",
    "image.show()\n",
    "\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# run the inference\n",
    "prediction = model.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2de7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import beepy\n",
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QLabel, QVBoxLayout, QWidget\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "from PyQt5.QtCore import QTimer, Qt\n",
    "from PyQt5 import QtGui\n",
    "\n",
    "# 컴퓨터에 내장된 소리를 출력\n",
    "def beepsound():\n",
    "    beepy.beep(sound=6)\n",
    "\n",
    "# image preprocessing\n",
    "def preprocessing(frame):\n",
    "    # Resize\n",
    "    size = (224, 224)\n",
    "    frame_resized = cv2.resize(frame, size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # normalize image\n",
    "    frame_normalized = (frame_resized.astype(np.float32) / 127.0) - 1\n",
    "\n",
    "    # Reshape image dimensions - reshape them for prediction.\n",
    "    frame_reshaped = frame_normalized.reshape((1, 224, 224, 3))\n",
    "\n",
    "    return frame_reshaped\n",
    "\n",
    "## Load the trained model\n",
    "model_filename = 'C:/Users/82102/res/dont_sleep/converted_keras/keras_model.h5'\n",
    "model = tensorflow.keras.models.load_model(model_filename)\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "    sleep_cnt = 1 # 30초간 \"졸림\" 상태를 확인하기 위한 변수\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.text_label = QLabel(self)\n",
    "        self.text_label.setAlignment(Qt.AlignCenter)\n",
    "        \n",
    "        # Create a label to display the webcam stream\n",
    "        self.label = QLabel(self)\n",
    "        self.label.setAlignment(Qt.AlignCenter)\n",
    "\n",
    "        # Create a layout for the label\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.label)\n",
    "        layout.addWidget(self.text_label)\n",
    "        \n",
    "        self.text_label.setText(\"Some text\")\n",
    "\n",
    "        # Create a central widget and set the layout\n",
    "        central_widget = QWidget()\n",
    "        central_widget.setLayout(layout)\n",
    "        self.setCentralWidget(central_widget)\n",
    "\n",
    "        # camera capture object, 0=internal camera, 1=external camera\n",
    "        self.capture = cv2.VideoCapture(0)\n",
    "\n",
    "        # Adjust capture frame size\n",
    "        self.capture.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "        self.capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "\n",
    "        # Create a timer to update the label with the webcam stream\n",
    "        self.timer = QTimer()\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "        self.timer.start(50)\n",
    "\n",
    "    def update_frame(self):\n",
    "        \n",
    "        ret, frame = self.capture.read()\n",
    "\n",
    "        if ret:\n",
    "            # flip image\n",
    "            frame_flipped = cv2.flip(frame, 1)\n",
    "\n",
    "            # data preprocessing\n",
    "            preprocessed = preprocessing(frame_flipped)\n",
    "\n",
    "            # prediction\n",
    "            prediction = model.predict(preprocessed)\n",
    "            # print(prediction) # [[0.00533728 0.99466264]]\n",
    "\n",
    "            if prediction[0,0] < prediction[0,1]:\n",
    "                print('졸림 상태')\n",
    "                MainWindow.sleep_cnt += 1\n",
    "                # 졸린 상태가 30초간 지속되면 소리 \n",
    "                if MainWindow.sleep_cnt % 100 == 0:\n",
    "                    MainWindow.sleep_cnt = 1\n",
    "                    print('30초간 졸고 있네요!!!')\n",
    "                    beepsound()\n",
    "                    # break ## 1번만 알람이 오면 프로그램을 정지 시킴 (반복을 원한다면, 주석으로 막기!)\n",
    "            else:\n",
    "                print('깨어있는 상태')\n",
    "                MainWindow.sleep_cnt = 1\n",
    "\n",
    "            # Convert the frame to a QImage\n",
    "            image = QImage(frame_flipped, frame_flipped.shape[1], frame_flipped.shape[0], \n",
    "                           frame_flipped.shape[1] * 3, QImage.Format_BGR888)\n",
    "\n",
    "            # Convert the QImage to a QPixmap and set it as the label's pixmap\n",
    "            pixmap = QPixmap.fromImage(image)\n",
    "            self.label.setPixmap(pixmap)\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        # Release the camera and stop the timer when closing the window\n",
    "        self.capture.release()\n",
    "        self.timer.stop()\n",
    "        super().closeEvent(event)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication([])\n",
    "    window = MainWindow()\n",
    "    window.show()\n",
    "    app.exec_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
